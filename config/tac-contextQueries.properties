# add the correct candidate to the result set
useOracleCandidateGeneration=false

galagoUseLocalIndex=true
galagoJsonParameterFile=./config/galago-fullwiki
galagoFullWikiJsonParameterFile=./config/galago-fullwiki

# galago server for http requests
#galagoKbSrv=avon3

# galago server port for http requests
# -- search only anchor text and titles
#galagoKbPort=10002
# -- full search
#galagoKbPort=10002
# ------------------------------------

# max number of candidates returned by candidate generator      
candidates.maxCandidates=100
useTacAndFullWiki=false
candidates.maxNuissanceCandidates=5
neighborhood.maxClosestNuissanceMentions=10
useCachedCandidatesFromRunFile=false
candidateFileKey=default
neighborCandidateFileKey=neighbor
neighborTrainCandidateFileKey=neighborTrain
galagoRunDir=candidates
usenerinquery=true
pseudo.useforfeatures=true
pseudo.candidates.maxCandidates=30
pseudo.querytype=seqdep
nerneighborquerymethod=discount
nerneighborqueryselectmethod=all
nerneighborquery_k=20
use_sentences_in_candidate_query=true
no_first_pass_query=false

# query for candidates
candidates.queryType=seqdep
features.redisFeatureSetName=rank # nonlp,llcsurf,galago
features.redisFeatureSetName.entity2entity=neighbor # umassText
features.redisFeaturePort=6380
features.redisFeatureSvr=avon3

# If true, precomputed features will be loaded from redis, otherwise they will be loaded on the fly
features.useCachedFeatures=false
features.useCachedFeatures.e2e=false
# if true existing feature vectors will be regenerated and overwritten.
features.redisOverwriteExisting=false
features.redisOverwriteExisting.e2e=false
# ---------------------


# max number of training examples considered  -- omit or use -1 for no restrictions    
pipeline.numTrainQueries=-1
# max number of test examples considered  -- omit or use -1 for no restrictions
pipeline.numTestQueries=-1

pipeline.crossval=false

# if true, model will be trained; if false parameters are loaded from disc
pipeline.retrainModel=true


# which feature sets to use for ranking. example: "nus,llcsurc" for NUS and LLC's surface features
features.ranking=queryonly,namevar,localcontext,galago
features.nil=nonlp,llcsurf,galago
features.neighborlinking=umassText



#  path to tab separated file for entity id conversion
idmapping=/iesl/canvas/jdalton/tac/data/tac-wiki-mapping

####### NLP Preprocessing
# path to extraction results (xml) from Stanford CoreNLP pipeline
# (copy from blake:/iesl/canvas/dietz/tacnlpextract/stanf/*.xml)
nlpextract.pathstanford=/iesl/canvas/dietz/tacnlpextract/stanf-sam2/
#nlpextract.pathstanford=/iesl/canvas/harshal/tacnlpextract/stanf-tacandfull_bkp/
nlpextract.outputpathstanford=/iesl/canvas/jdalton/tmp/

# file that collects filenames to be extracted
nlpextract.liststanford=/iesl/canvas/jdalton/tacnlpextract/extractStanfList-sam.txt
# Shell script for NLP processing will be written here
nlpextract.scriptstanford=/iesl/canvas/jdalton/tacnlpextract/extractStanf.sh
# path to stanford extractor (needed only for shell script creation)
nlpextract.execstanford=/iesl/canvas/jdalton/development/git/tacco/lib/stanford-corenlp-2012-04-09

serialcomention.path=/iesl/canvas/jdalton/tac/data/candidateFeatures_allv5_newfeatures_no_oracle
#serialcomention.path=/iesl/canvas/jdalton/tac/data/candidateFeatures_2012/

galago.termcounts=/iesl/canvas/jdalton/tac/full-wiki-stats

filterNoNlpInfo=false
eval.printranking=true
debug.parallelProcessing=false
pipeline.modelFile=neighbormodel
eval.detailedOutput=neighbor100.txt
